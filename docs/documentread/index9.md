# SeFAR: Semi-supervised Fine-grained Action Recognition with Temporal Perturbation and Learning Stabilization

过去一年多模态大语言模型（MLLMs）进步很大，追求更通用的能力；但是可能牺牲特定任务的表现，所以作者选择专注特定任务，来提升模型的细粒度理解能力。

论文评估了四个多模态大语言模型，都无法正确识别给定动作的细粒度语义。


#

这个图是 SeFAR 流程概览。他是提出了三个策略：

1. 双层时序元素，包括 细粒度时间元素 和 时间上下文
2. 细粒度时序元素的扰动，一种新的强增强策略，同时保持上下文元素的时间顺序
3. 自适应调节机制，通过计算系数调整损失来稳定训练过程

# Dual-level Temporal Elements双层时序元素

1. 给定一个包含 N 帧的细粒度动作视频，首先将其裁剪为K个片段，得到帧序列：{f_1,f_2,...,f_k}
2. 构建若干个小的时间元素 pi，经过 M 次采样，得到一组具有相同时间长度的时间元素。pi包含L帧
3. 最后获取一个上下文元素 p_context 用于编码长期信息和宏观时序动态，这个 上下文元素由更多帧构成

# Perturbation of Fine-grained Temporal Elements 细粒度时序元素的扰动

它的方法很简单，就是 反转帧顺序，但是 上下文元素 不进行这个扰动。

# Stabilizing Optimization via Adaptive Regulation 通过自适应调节实现稳定优化

最后就是 通过自适应调节实现稳定优化。

教师模型这种不稳定的预测会给学生模型带来模棱两可且无效的伪标签，从而影响整个学习过程。

1. 让教师模型为一个给定的未标记视频生成 U 次预测（在实验中，U 设为 10），这些预测可能会有很大差异。

2. 基于这些预测为每个类别计算平均预测置信度和标准差。对于第 i 次预测，所有类别上的预测概率构成一个概率分布，可以得到最大预测置信度值 μᵢ，并计算其标准差。我们选取最高的置信度值，以及其对应的标准差

基于上述的 置信度 μ* 和标准差 σ* ，计算动态系数 τ1 和 τ2 ，用于调整来自未标记样本的损失。

当 μ ∗ 增大时，τ1  会迅速增加，从而增强高置信度预测

τ2 ​会抑制即具有较高标准差 σ 的这种不稳定的预测

然后得到一个τ1⋅τ2的自适应系数。

之后还采用了SVFormer相同的混合策略——tubemix。其中两个无标签样本的混合 λ ⁢x1 + (1−λ) ⁢x2 。也作为输入，然后计算了这个新的系数 η 。其中 η1,η2 是根据 x1 和 x2 分别计算的。

最后就是这个总损失。

# 实验部分

在这两个数据集上都更好。

这个是在粗粒度的数据集实验，与半监督方法的比较。

## 消融实验
表三：表明每个模块都做出了贡献

下图a：即使输入只有 6 帧， 即 {2-4}，我们提出的 SeFAR 也超过了 8 帧输入baseline ——SVFormer 。
增加细粒度元素的数量， 即 {2-2-2-4}，或延长上下文元素的时间长度， 即 {2-2-6}和{2-2-8}，都会导致性能提升。这是因为更多的帧包含更丰富的动作信息

表四：它的时间扰动方法展现出其稳定性和有效性。S 和 O 分别表示侧重于速度（Speed-focused）和顺序（Order-focused）的增强方法。

下图b：为了证明我们为自适应损失设计的“稳定系数”的实用性，我们进行了两项分析。图b显示出固定阈值方法（蓝色线）则随阈值变化而波动

下图c：展现了教师模型在FAR任务中的不稳定预测，FineGym波动很大，体现了 稳定机制 的必要性。

## 
