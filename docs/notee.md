# test
## Stage1:
Two-Stream Convolutional Networks for Action Recognition in Videos

Temporal Segment Networks: Towards Good Practices for Deep Action Recognition

Learning Spatiotemporal Features with 3D Convolutional Networks

Quo Vadis,Action Recognition? A New Model and the Kinetics Dataset

TSM: Temporal Shift Module for Efficient Video Understanding

TEA: Temporal Excitation and Aggregation for Action Recognition

TDN: Temporal Difference Networks for Efficient Action Recognition

(数据集)FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding

## Stage2：
基础论文：Attention is all you need

基础论文：（ViT）AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE

基础论文：Vivit: A video vision transformer 

基础论文：Swin-Transformer

Is space-time attention all you need for video understanding? 

Multiview transformers for video recognition

UniFormer: Unified Transformer for Efficient Spatiotemporal Representation Learning, ICLR22

UniFormerV2: spatiotemporal learning by arming image vits with video uniformer 

## Stage3-视觉语言模型：
基础论文：Learning Transferable Visual Models From Natural Language Supervision
Bidirectional Cross-Modal Knowledge Exploration for Video Recognition with Pre-trained Vision-Language Models, CVPR23

VicTR: Video-conditioned Text Representations for Activity Recognition, CVPR24
Language Model Guided Interpretable Video Action Reasoning, CVPR24

Leveraging Entity-to-Region Alignments for Generalizable Video Action Recognition, CVPR24

OST: Refining Text Knowledge with Optimal Spatio-Temporal Descriptor for General Video Recognition, CVPR24

## Stage4-视频问答模型：
Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models

VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding, ECCV 2024

SlowFocus: Enhancing Fine-grained Temporal Understanding in Video LLM (NeurIPS 2024)

VideoChat : Chat-Centric Video Understanding

MovieChat: From Dense Token to Sparse Memory for Long Video Understanding